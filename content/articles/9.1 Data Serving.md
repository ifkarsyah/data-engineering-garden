You've ingested your data from your source system, stored it, and transformed it into something useful. It's finally time to serve it for higher-level tasks such as analytics, machine learning, and reverse ETL. We take a closer look at analytics and machine learning and the ways you can serve data for each of these tasks. However, let's consider some general factors to consider before serving data.

## Factors To Consider When Serving Data

### Trust

"Garbage in garbage out", is a popular analogy in machine learning. It refers to the fact that if the data you used to train a model is worthless the predictions made by that model are also worthless. The data you provide as a data engineer needs to be trusted by the people going to use that data. You can establish trust through the following ways:

1. **Data validation and Data observability**: Consistently check your data accuracy and offer a continuous view of your data and its processes.
2. **Service Level Agreements(SLAs) and Service Level Objectives (SLOs)**: These are commitments made by data engineers to end-users regarding data availability and quality. SLAs are contracts with users stating what they can expect, while SLOs are specific metrics for measuring performance against these expectations. Data engineers need to communicate clearly about these agreements and constantly ensure that they are meeting the set standards.
3. **Ongoing Communication:** As with all relationships communication is key, ensure that you communicate any potential issues that might affect your SLAs or SLOs and possible solutions to the relevant stakeholders.

### Use-Case and the User

The productive use of data is determined by its ability to lead to actionable outcomes. This goes beyond just generating reports and dashboards. Data becomes valuable when it informs decision-making or triggers specific actions.

The key is to always consider what action the data will initiate and who will be responsible for that action, including the possibility of automating the action. This consideration should lead to you prioritising use cases based on their ROI (Return On Investment) rather than getting caught up in the technical aspect.

It's also important that when starting a new data project, a data engineer should consider the use and use case before diving into the tools.

### Data Products

Creating effective data products in data engineering involves a comprehensive understanding of user needs and the intended purpose of the product. It requires collaborative efforts, integrating insights from business, technology, and product management. Key to success is the concept of 'jobs to be done,' where understanding what task the user is hiring the data product for is critical. This approach prevents the common pitfalls of developing products without market fit or user demand. Effective data products also benefit from positive feedback loops, where user engagement leads to improved data quality and product refinement. Consideration of whether the product serves internal or external users, alongside its outcomes and return on investment, is crucial. Monitoring user adoption and being open to adjustments based on feedback ensures the product remains relevant and trusted.

### Self-Service or Not?

Implementing self-service data products, which enable users to independently create reports, analyses, and machine learning models, presents significant challenges in practice, despite being a desirable goal in data management. The success of these products hinges on accurately understanding the users' needs and capabilities. For instance, executives might prefer predefined dashboards, while data analysts may require more advanced tools. Identifying the appropriate audience, such as data-savvy executives or business leaders willing to learn, is crucial. The implementation must also consider the users' time requirements, anticipate their evolving needs, and strike a balance between providing flexibility and ensuring accuracy to prevent confusion and incorrect results. The effectiveness of self-service data products is therefore contingent on a tailored approach that aligns with the specific skills and objectives of its users.

### Data Definitions and Logic

The utility of data in an organization crucially depends on its correctness and trustworthiness, which go beyond mere accurate reproduction from source systems. Two vital aspects are data definition, which ensures a uniform understanding of data terms across the organization, and data logic, which involves the rules for deriving metrics from data. Often, organizations rely on informal institutional knowledge for these aspects, which can lead to inconsistencies. Formalizing data definitions and logic in a data catalogue and integrating them throughout the data engineering lifecycle is key to maintaining data correctness and consistency. Using a semantic layer can further consolidate these definitions and logic, allowing for a consistent, reusable approach across various applications, and enhancing the overall trustworthiness and utility of the data.

### Data Mesh

The concept of Data Mesh is becoming increasingly important in the context of how data is served within organizations. Data Mesh represents a shift from traditional, siloed data teams to a more decentralized, peer-to-peer approach. In this model, each domain team within an organization takes on two main responsibilities:

1. **Serving Data to Other Teams**: Teams are responsible for preparing and serving data for consumption by other teams. This involves ensuring that the data is ready and suitable for use in various applications such as data apps, dashboards, analytics, and business intelligence (BI) tools. The focus is on making data accessible and usable across different parts of the organization.
2. **Running Dashboards and Analytics for Self-Service**: In addition to serving data, each team also manages its dashboards and analytics for self-service purposes. This means they consume data from across the organization, tailored to the specific needs of their domain. The data received from other teams may be integrated into the team's software applications, including embedded analytics or machine learning features.

This approach to data management through Data Mesh changes the traditional structure of data serving. It fosters a more collaborative and interconnected data environment where teams are both providers and consumers of data, facilitating a more efficient and holistic use of data within the organization.

## Analytics

Analytics in data-serving use cases is multifaceted, encompassing the discovery, exploration, identification, and visualization of key insights and patterns within data. It employs statistical methods, reporting, business intelligence (BI) tools, and more. Data engineers must be well-versed in various analytics types and techniques to effectively serve data for these purposes.

There are three primary categories of analytics:

1. **Business Analytics**: This type focuses on using historical and current data for strategic decision-making, combining statistical and trend analysis with domain expertise and judgment. It's often expressed through dashboards, reports, and ad-hoc analysis. Dashboards provide a concise overview of core metrics, reports drive insights and action from data, and ad-hoc analysis tackles specific, often spontaneous queries. The data for business analytics is typically served from data warehouses or lakes and may vary in update frequency.
2. **Operational Analytics**: This form of analytics is centered on using data for immediate action, contrasting with the longer-term perspective of business analytics. Examples include real-time application monitoring and instant issue resolution. The emphasis is on up-to-the-second updates and the immediate impact of the data.
3. **Embedded Analytics**: This growing trend involves integrating analytics into user-facing applications, allowing end-users to make decisions based on real-time data. Embedded analytics is characterized by low latency, fast query performance, and high concurrency to cater to app users' expectations for immediate, responsive data interaction.

The evolution of data analytics is moving towards real-time data processing, with streaming data expected to become more prevalent. Data engineers play a crucial role in this landscape, managing technical backend aspects and adapting to the changing demands of analytics, whether for internal decision-making or external user applications. Understanding the specific needs and use cases of each analytics type is essential for data engineers to effectively serve and manage the data.

## Machine Learning

Machine Learning (ML) represents a significant area in the realm of data serving, where the roles of data engineers intersect with ML engineers and data scientists. The integration of ML in various organizational processes has led to the emergence of ML engineering as a distinct discipline, often overlapping with data engineering.

In this collaborative environment, the role of a data engineer can vary widely depending on the organization. In some cases, data engineers are responsible for processing data up to a certain point in the ML lifecycle, after which ML engineers take over, particularly for tasks like model training. Data engineers might also be involved in more specialized ML tasks, such as data featurization, where they prepare data in a format that is suitable for ML models.

This interplay is exemplified in scenarios where data engineers work alongside data scientists and ML engineers to optimize processes or products. For instance, in a manufacturing context, data engineers might collaborate with data scientists to develop models that improve production quality, and with ML engineers to automate and refine these models. The data engineer's role is pivotal in ensuring that the data is appropriately processed and maintained for effective use in ML applications, highlighting the increasingly collaborative and interdisciplinary nature of data-driven projects.

## Conclusion

We will discuss how to serve data in a subsequent article.