Data engineering is an ever-evolving field. This article looks at some of the possible ways data engineering could transform in the future through the lens of Joe Reis and Matthew Housley.

### Data Engineering Is Here To Stay

Data engineering is becoming a critical and rapidly growing field in technology, necessary for building the foundational systems needed for advanced applications like AI and ML. Despite the development of simpler tools, the role of data engineers remains vital. They are essential in designing, building, and maintaining complex data systems and workflows. As tools evolve, data engineers are expected to focus on more high-level, complex tasks, ensuring their continued importance in the tech industry.

### The Reign of Simple User-Friendly Tools

The field of data engineering is becoming more accessible due to the development of simplified, user-friendly tools. This evolution is beneficial amid a shortage of data engineers. The adoption of cloud computing and Software as a Service (SaaS) has made advanced data technologies available to all companies, not just large ones. Cloud services have simplified the use of open-source tools, offering managed services that are as easy to use as proprietary ones. Additionally, the rise of off-the-shelf data connectors like Fivetran and Airbyte has reduced the workload of data engineers, allowing them to focus on more unique tasks. As a result, the field of data engineering is growing, with tools becoming less complex while gaining more features, making data engineering more accessible to a wider range of companies.

### Evolution of Cloud Data Services and the Future Role of Data Engineers

Services like Google Cloud BigQuery, Azure Blob Storage, Snowflake, and AWS Lambda function similarly to operating system services, but on a larger scale across multiple machines. This simplifies data handling in the cloud, akin to how operating systems manage hardware resources for applications.

The future of cloud data services involves standardizing data APIs to streamline building data pipelines and applications, with advancements in file formats like Parquet and Avro for better data interchange. Metadata catalogues will become increasingly important for data interoperability and automation.

Data orchestration platforms, such as Apache Airflow, are evolving to integrate more closely with data cataloguing and become more data-aware, incorporating infrastructure as code capabilities for more efficient pipeline management.

Furthermore, advancements in live data processing and streaming data architectures are simplifying the deployment and management of complex data systems.

As these technologies develop, the role of the data engineer will evolve to focus on building more sophisticated data applications and systems, adapting to the increased interoperability and simplicity in the cloud data environment.

### Embracing Enterprise

The field of data engineering is evolving towards a more structured, organized approach often associated with large enterprises. This shift is due to the simplification of data tools and the establishment of best practices in the industry. The term "enterprisey" might initially evoke negative images of bureaucratic inefficiencies and stifled innovation. However, in this context, it signifies the adoption of effective management, operations, and governance practices that have been successful in larger companies.

This new phase in data engineering is characterized by the adoption of technologies and practices that were previously exclusive to big organizations. Key aspects of big data and streaming data, which were once challenging, are now becoming more accessible and user-friendly. The focus is shifting towards ease of use, interoperability, and refinement of these tools.

As a result, data engineers are finding new opportunities in the simplified and abstracted layers of data management and DataOps. These developments allow data engineers to embrace the positive aspects of "enterprisey" approaches, such as structured management and efficient operations, enhancing their role and impact in the field.

### Blurring Boundaries and Emerging Roles in Data Engineering and ML

The distinction between various data-related fields such as software engineering, data engineering, data science, and machine learning (ML) engineering is becoming increasingly blurred. Many data scientists, for example, have transitioned to data engineering roles out of necessity, building systems to support data engineering tasks.

As tools and processes become simpler and more efficient, data scientists and engineers will spend less time on repetitive, low-level tasks. For data scientists, this means dedicating less time to data gathering and preparation. For data engineers, it involves moving away from tasks like server management and configuration. This shift is leading to a more structured, "enterprisey" approach in data engineering, focusing on management and operations.

The evolving landscape also suggests the emergence of new roles at the intersection of these fields. One such role might be a hybrid of ML engineering and data engineering, focusing on operationalizing machine learning processes. These professionals would be skilled in algorithms, ML techniques, model optimization, and monitoring, as well as managing automated systems for model training and performance monitoring.

Another evolving area is the convergence of software engineering and data engineering. As data applications that integrate analytics with traditional software become more common, software engineers will need to develop a deeper understanding of data engineering concepts like streaming, data pipelines, and data modelling. This shift will lead to more integrated teams where data engineers and software developers work closely together, breaking down the traditional barriers between application backend systems and data engineering tools. This integration is likely to be facilitated through streaming and event-driven architectures.

### Transitioning to Real-Time Data Applications: Beyond the Modern Data Stack

The modern data stack (MDS), while praised for democratizing powerful data tools, is seen as a repackaging of old data warehouse practices using modern technologies. However, the data world is moving beyond this, especially towards real-time data applications. The trend is shifting from internal analytics and data science to powering businesses and applications in real time with advanced databases.

The evolution is driven by the shift from analytics to automation, with actions based on real-time data rather than reports. Products like TikTok, Uber, and Google exemplify real-time data applications, offering sophisticated, low-latency data processing and ML. This level of technology, once exclusive to large tech companies, is becoming more accessible.

The next phase is the 'Live Data Stack,' integrating real-time analytics and ML into applications using streaming technologies. This stack will transform how data is processed and utilized, making real-time data application technologies available to a broader range of companies.

Key components of this shift include streaming pipelines and real-time analytical databases. These technologies treat data as an unbounded, continuous stream, in contrast to the batch techniques of the MDS. This approach enables faster ingestion and querying of data, offering new possibilities beyond the limitations of traditional data processing.

Data transformations will also evolve, moving from ELT to a streaming-focused approach. While batch processing will still have its uses, streaming transformation will become more common, particularly with databases optimized for streaming.

Additionally, the fusion of application and data layers is anticipated, integrating real-time automation and decision-making into applications. This integration will shorten the time between stages in the data engineering lifecycle and foster innovations in database technologies.

Finally, the fusion of applications and ML will tighten the feedback loop between them. Most applications will integrate ML as data sizes and velocities increase. This integration will create a cycle of increasingly intelligent applications, enhancing business value.

In conclusion, the data world is transitioning from traditional, batch-oriented processes to a more dynamic, real-time approach, reshaping the landscape of data engineering and application development.